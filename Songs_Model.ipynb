{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1d18d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import wave\n",
    "import contextlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9c998c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "click = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ecaa6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X = np.load(\"X.npy\")\n",
    "    Y = np.load(\"Y.npy\")\n",
    "except:\n",
    "    click = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "74ad86f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'Beatles',\n",
       " 'Others',\n",
       " 'Led Zeppelin',\n",
       " 'Nirvana',\n",
       " 'Pink Floyd',\n",
       " 'Elvis Presley',\n",
       " 'Beach Boys',\n",
       " 'Queen',\n",
       " 'Bob Dylan']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Training_Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ad379084",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, sr1 = librosa.load(\"/Users/viralchitlangia/Documents/Songs_Audio_Trial/Training_Files/Beatles/ISawHerStandingThereRemastered2009.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "caaca3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 7493)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.feature.mfcc(y = y1, sr = sr1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8d1af26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2, sr2 = y2, sr2 = librosa.load(\"/Users/viralchitlangia/Documents/Songs_Audio_Trial/Training_Files/Beatles/WhileMyGuitarGentlyWeepsRemastered2009.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ba43d06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 12275)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.feature.mfcc(y = y2, sr = sr2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "194d037e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12275"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(librosa.feature.mfcc(y = y2, sr = sr2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7aab4ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285.00172335600905\n"
     ]
    }
   ],
   "source": [
    "fname = '/Users/viralchitlangia/Documents/Songs_Audio_Trial/Training_Files/Beatles/WhileMyGuitarGentlyWeepsRemastered2009.wav'\n",
    "with contextlib.closing(wave.open(fname,'r')) as f:\n",
    "    frames = f.getnframes()\n",
    "    rate = f.getframerate()\n",
    "    duration = frames / rate\n",
    "    print((duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "12eb3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(filename):\n",
    "    with contextlib.closing(wave.open(filename,'r')) as f:\n",
    "        frames = f.getnframes()\n",
    "        rate = f.getframerate()\n",
    "        duration = frames / rate\n",
    "        return int(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fe0e7e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 0, 0, 0]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def near_empty_array(x, n):\n",
    "    y = [x]\n",
    "    for i in range(0, n - 1):\n",
    "        y.append(0)\n",
    "    return y\n",
    "\n",
    "near_empty_array(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "514eeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if click == 0:\n",
    "    X = []\n",
    "    Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "371f275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if click == 0:\n",
    "    for x in os.listdir(\"Training_Files\"):\n",
    "        if x != \".DS_Store\":\n",
    "            k = os.listdir(\"Training_Files/\" + x)\n",
    "            for j in tqdm(range(0, len(k))):\n",
    "                if k[j] != \".DS_Store\":\n",
    "                    y, sr = librosa.load(\"Training_Files/\" + x + \"/\" + k[j])\n",
    "                    mfcc = librosa.feature.mfcc(y = y, sr = sr)\n",
    "                    mfcc = np.resize(mfcc, (20, 10000))\n",
    "                    time = duration(\"Training_Files/\" + x + \"/\" + k[j])\n",
    "                    row = near_empty_array(time, 10000)\n",
    "                    mfcc = np.vstack([mfcc, row])\n",
    "                    X.append(mfcc.tolist())\n",
    "                    Y.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b5a9ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if click == 0:\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    np.save(\"X.npy\", X)\n",
    "    np.save(\"Y.npy\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6ba23fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beach Boys', 'Beatles', 'Bob Dylan', 'Elvis Presley',\n",
       "       'Led Zeppelin', 'Nirvana', 'Others', 'Pink Floyd', 'Queen'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "23cc24d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LabelEncoder()\n",
    "l.fit(Y)\n",
    "Y_t = l.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fff0e0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1d7d377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_t, test_size=0.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4d666efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909, 21, 10000)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "66f19ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(32, 2, activation='relu', input_shape=(21, 10000)))\n",
    "#model.add(layers.AvgPool2D((2, 2)))\n",
    "#model.add(layers.BatchNormalization(synchronized=True))\n",
    "model.add(layers.Conv1D(64, 2, activation='relu'))\n",
    "#model.add(layers.AvgPool1D(2))\n",
    "model.add(layers.BatchNormalization(synchronized=True))\n",
    "model.add(layers.Conv1D(128, 4, activation='relu'))\n",
    "model.add(layers.AvgPool1D(2))\n",
    "model.add(layers.BatchNormalization(synchronized=True))\n",
    "model.add(layers.Conv1D(256, 3, activation='relu'))\n",
    "model.add(layers.AvgPool1D(2))\n",
    "model.add(layers.BatchNormalization(synchronized=True))\n",
    "model.add(layers.Conv1D(512, 3, activation='relu'))\n",
    "#model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.BatchNormalization(synchronized=True))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(17, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9e1cbcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_50 (Conv1D)          (None, 20, 32)            640032    \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 19, 64)            4160      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 19, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 16, 128)           32896     \n",
      "                                                                 \n",
      " average_pooling1d_14 (Avera  (None, 8, 128)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 8, 128)           512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 6, 256)            98560     \n",
      "                                                                 \n",
      " average_pooling1d_15 (Avera  (None, 3, 256)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 3, 256)           1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_54 (Conv1D)          (None, 1, 512)            393728    \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 1, 512)           2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 17)                561       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,208,689\n",
      "Trainable params: 1,206,769\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "46369855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 7s 66ms/step - loss: 2.3627 - accuracy: 0.3036 - val_loss: 21.2656 - val_accuracy: 0.1191\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 1s 48ms/step - loss: 1.7374 - accuracy: 0.3982 - val_loss: 10.5309 - val_accuracy: 0.1211\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.5830 - accuracy: 0.4323 - val_loss: 3.3592 - val_accuracy: 0.2539\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.5329 - accuracy: 0.4389 - val_loss: 2.2658 - val_accuracy: 0.2930\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.4743 - accuracy: 0.4642 - val_loss: 2.2602 - val_accuracy: 0.3320\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 1s 48ms/step - loss: 1.4383 - accuracy: 0.4587 - val_loss: 1.8822 - val_accuracy: 0.3789\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.3703 - accuracy: 0.5050 - val_loss: 1.8027 - val_accuracy: 0.4199\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 1.4123 - accuracy: 0.4884 - val_loss: 2.1081 - val_accuracy: 0.4199\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.2931 - accuracy: 0.5193 - val_loss: 1.7837 - val_accuracy: 0.3945\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.2681 - accuracy: 0.5204 - val_loss: 1.7783 - val_accuracy: 0.4062\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 1.1663 - accuracy: 0.5567 - val_loss: 2.1238 - val_accuracy: 0.3105\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.2578 - accuracy: 0.5391 - val_loss: 2.0960 - val_accuracy: 0.4238\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.1751 - accuracy: 0.5501 - val_loss: 2.1157 - val_accuracy: 0.3867\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.0763 - accuracy: 0.5721 - val_loss: 1.9840 - val_accuracy: 0.4238\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 0.9781 - accuracy: 0.6425 - val_loss: 5.1557 - val_accuracy: 0.2383\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 1s 49ms/step - loss: 0.9643 - accuracy: 0.6513 - val_loss: 4.6719 - val_accuracy: 0.2461\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 1.0026 - accuracy: 0.6524 - val_loss: 3.3910 - val_accuracy: 0.3301\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 0.9962 - accuracy: 0.6260 - val_loss: 2.3459 - val_accuracy: 0.3750\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 0.8955 - accuracy: 0.6854 - val_loss: 4.1145 - val_accuracy: 0.2637\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 0.8406 - accuracy: 0.6733 - val_loss: 3.1122 - val_accuracy: 0.3457\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 0.8557 - accuracy: 0.7030 - val_loss: 3.4383 - val_accuracy: 0.3965\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 0.6725 - accuracy: 0.7536 - val_loss: 3.9902 - val_accuracy: 0.3301\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 0.5993 - accuracy: 0.7910 - val_loss: 2.4842 - val_accuracy: 0.4551\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 1s 48ms/step - loss: 0.6568 - accuracy: 0.7712 - val_loss: 2.7017 - val_accuracy: 0.3438\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 1s 48ms/step - loss: 0.6539 - accuracy: 0.7811 - val_loss: 3.2984 - val_accuracy: 0.3301\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 1s 51ms/step - loss: 0.6821 - accuracy: 0.7701 - val_loss: 3.0341 - val_accuracy: 0.3340\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 0.7087 - accuracy: 0.7723 - val_loss: 2.5184 - val_accuracy: 0.4004\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 0.5234 - accuracy: 0.8372 - val_loss: 2.6486 - val_accuracy: 0.4473\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 0.4557 - accuracy: 0.8482 - val_loss: 3.4725 - val_accuracy: 0.4004\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 0.3972 - accuracy: 0.8515 - val_loss: 3.0270 - val_accuracy: 0.4023\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-2),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=30, \n",
    "                    validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7306c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1e1813aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22027676594582002"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
